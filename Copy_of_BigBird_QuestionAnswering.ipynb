{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqMCml8QHkfH",
        "outputId": "e2f04e31-cc29-4ea6-dd65-5eb22da630f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rifnyOyNWsg",
        "outputId": "9a49861f-f678-4e40-b21d-fcd989a93756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to remove any special characters in the file\n",
        "import re\n",
        "file_path = '/content/INCORPORATEDFULL.txt'\n",
        "def remove_invalid_characters(file_path):\n",
        "  with open(file_path, 'r') as file:\n",
        "    content = file.read()\n",
        "# Define the pattern to match the invalid characters\n",
        "\n",
        "  pattern = r'[^\\x00-\\x7F]'\n",
        "# Remove the invalid characters using the sub() method\n",
        "  cleaned_content = re.sub(pattern, '', content)\n",
        "# Write the cleaned content back to the file\n",
        "  with open(file_path, 'w') as file:\n",
        "    file.write(cleaned_content)\n",
        "\n",
        "remove_invalid_characters(file_path)"
      ],
      "metadata": {
        "id": "GBJsLUdcda_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BigBirdTokenizer, BigBirdForQuestionAnswering\n",
        "\n",
        "# # by default its in `block_sparse` mode with num_random_blocks=3, block_size=64\n",
        "# model = BigBirdForQuestionAnswering.from_pretrained(\"google/bigbird-base-trivia-itc\")\n",
        "\n",
        "# # you can change `attention_type` to full attention like this:\n",
        "# model = BigBirdForQuestionAnswering.from_pretrained(\"google/bigbird-base-trivia-itc\", attention_type=\"original_full\")\n",
        "\n",
        "# you can change `block_size` & `num_random_blocks` like this:\n",
        "model = BigBirdForQuestionAnswering.from_pretrained(\"google/bigbird-base-trivia-itc\", block_size=16, num_random_blocks=2)\n",
        "\n",
        "tokenizer = BigBirdTokenizer.from_pretrained(\"google/bigbird-base-trivia-itc\")\n",
        "\n",
        "question = \"what is the number of Series Seed Compulsorily Convertible Nc Preference Shares of Rs. 100?\"\n",
        "with open(r'/content/INCORPORATEDFULL.txt', 'r') as file:\n",
        "  context = file.read()\n",
        "  # print(context)\n",
        "# context = \"Put some context for answering\"\n",
        "encoded_input = tokenizer(question, context, return_tensors='pt')\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    output = model(**encoded_input)\n",
        "\n",
        "# Get the start and end indices of the answer span\n",
        "start_index = torch.argmax(output.start_logits)\n",
        "end_index = torch.argmax(output.end_logits)\n",
        "\n",
        "# Get the answer text from the tokenized input\n",
        "answer = tokenizer.decode(encoded_input[\"input_ids\"][0][start_index:end_index+1])\n",
        "\n",
        "print(\"Answer:\", answer)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYPcdv0IH_z7",
        "outputId": "31f67cb3-42c2-4d77-dc68-11ca7ea9e901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 7,000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. what is the number of Series Seed Compulsorily Convertible Nc Preference Shares of Rs. 100\n",
        "Answer: 7,000\n",
        "2. what is the number of Pre-Series Seed Compulsorily Convertible Nc Preference Shares of Rs. 10\n",
        "Answer: 7,000\n",
        "3. What is the number of Equity Shares of Rs. 10\n",
        "Answer: 28,000\n",
        "4. What is the Authorized Share Capital of the Company\n",
        "Answer: 1,060,000\n",
        "5. what is the total number of preference shares and their face value\n",
        "Answer: 7,000\n",
        "6. what is the total number of preference shares and their per share price\n",
        "Answer: [SEP]\n"
      ],
      "metadata": {
        "id": "Nn3XBZHPZu5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BigBirdTokenizer, BigBirdForQuestionAnswering\n",
        "\n",
        "# by default its in `block_sparse` mode with num_random_blocks=3, block_size=64\n",
        "model = BigBirdForQuestionAnswering.from_pretrained(\"google/bigbird-base-trivia-itc\")\n",
        "\n",
        "# # you can change `attention_type` to full attention like this:\n",
        "# model = BigBirdForQuestionAnswering.from_pretrained(\"google/bigbird-base-trivia-itc\", attention_type=\"original_full\")\n",
        "\n",
        "# # you can change `block_size` & `num_random_blocks` like this:\n",
        "# model = BigBirdForQuestionAnswering.from_pretrained(\"google/bigbird-base-trivia-itc\", block_size=16, num_random_blocks=2)\n",
        "\n",
        "tokenizer = BigBirdTokenizer.from_pretrained(\"google/bigbird-base-trivia-itc\")\n",
        "\n",
        "# question = \"The method that using images as the input can be divided into how many categories\"\n",
        "question = \"what is the purpose of pothole detection system\"\n",
        "with open(r'/bigbird_contextSample.txt', 'r') as file:\n",
        "  context = file.read()\n",
        "  print(context)\n",
        "# context = \"Put some context for answering\"\n",
        "encoded_input = tokenizer(question, context, return_tensors='pt')\n",
        "# Perform inference\n",
        "with torch.no_grad():\n",
        "    output = model(**encoded_input)\n",
        "\n",
        "# Get the start and end indices of the answer span\n",
        "start_index = torch.argmax(output.start_logits)\n",
        "end_index = torch.argmax(output.end_logits)\n",
        "\n",
        "# Get the answer text from the tokenized input\n",
        "answer = tokenizer.decode(encoded_input[\"input_ids\"][0][start_index:end_index+1])\n",
        "\n",
        "print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_kBurXTSZrh",
        "outputId": "5b0e68e6-5f23-4371-b7bb-89dd90655b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿Pothole Detection and Avoidance via Deep Learning on Edge Devices Chi-Wei Kuan Graduate Institute of Automation Technology National Taipei University of Technology Taipei, Taiwan h042910276@gmail.com Wen-Hui Chen Graduate Institute of Automation Technology National Taipei University of Technology Taipei, Taiwan whchen@ntut.edu.tw Yu-Chen Lin Department of Automatic Control Engineering Feng Chia University Taichung, Taiwan yuchlin@fcu.edu.tw Abstract—Hitting potholesġ can not only cause damage to vehicles but also put passengers into danger. However, due to the various factors, such as budget consideration and soil erosion, it is impossible to fix all the potholes onġthe roads. Instead of avoiding potholes directly, most researches tend to collect the position of potholes on the roads for developing more effective road maintenance strategies. In this paper, a pothole avoidance system deployed on an edge platform is proposed, which can avoid potholes automatically. We use Deep Q-Network (DQN) as an agent, and train it on CARLA driving simulator with cross-task unsupervised transfer learning. To accelerate the executing speed of the system on the edge platform, the model is quantized toġan 8- bit integer. Finally, we implement the pothole avoidance system on the Xilinx ZCU104 evaluation board, which is satisfied with the deployment limitations of vehicles, such as power consumption. To evaluate the proposed system, we have set up a virtual road environment with CARLA, and generated several potholes on the road randomly. Then, a vehicle controlled by the pothole avoidance system was tested in the environment. The evaluation results show that the proposed system can effectively reduce the opportunity of hitting potholes by 31% compared to the baseline. Besides, the system deployed on the Xilinx ZCU104 can execute at 30 FPS, and the energy efficiency is 0.91 FPS/W. In conclusion, the proposed system can effectively avoid potholes on the road, and its execution speed and power consumption meet the requirements of the actual driving situation. Keywords—Reinforcement Learning, Autonomous Driving, Edge Computing, Quantization, Pothole Avoidance System I. INTRODUCTION Autonomous vehicles have gradually received stronger attention due to its great commercial value, but they still have some safety issues that need to be overcome, such as hitting potholes. Hitting potholes can affect driving comfort and increase the maintenance costs of vehicles. Moreover, it can also endanger the lives of passengers. There were different kinds of approaches for detecting potholes have been proposed, such as vibration-based methods, depth-based methods, and image based methods. Although various approaches for pothole detection were proposed, none of them can actually prevent vehicles from hitting potholes. In this work, we implement a pothole detection system based on object detection, and further develop a pothole avoidance system, which can actively avoid hitting potholes. The proposed pothole detection system and pothole avoidance system responding to the following problems: A. Pothole detection system x Proposed a perspective bounding box that can represent the pothole more precisely than the bounding box. x Solved the problem that it’s hard to distinguish adjacent potholes with a region-based determination method. B. Pothole avoidance system x Further advance the research target from detecting the potholes to avoiding potholes. x Using a task-crossing transfer learning approach, which can take advantage of a pre-trained model. Also, the approach is label-free. II. RELATED WORK A. Pothole Detection Previous researches aim to collect the position of potholes on the roads for making more effective maintenance strategies. According to the type of input data, these methods can be concluded into three categories: vibration-based, depth-based, and image-based. Follows will describe the pros and cons of each method. 1) Vibration-based: Significant vibration signal is generated when a vehicle hitting a pothole, then the acceleration sensor built in the vehicle or the smartphone collects the vibration signal. Next, some machine learning algorithms [1] are used to determine whether the vehicle is hitting potholes, e.g., support vector machine, k-means clustering, random forest, Bayesian estimation, or unscented Kalman filter. The computations are done by a local server or cloud-computing. The vibration-based method has the advantages of low cost and easy implementation. However, this kind of method uses the vehicle as a probe, which can damage the vehicle and put the passenger into danger. On the other hand, this kind of method cannot perceive any pothole until the vehicle hit it. Therefore, it cannot take any action to protect the vehicle. 2) Depth-based: Potholes are parts of road surfaces lower than usual. According to this feature, depth-based approaches [2] measure the depth of the road surface with This research is supported by Ministry of Science and Technology (MOST) under MOST-109-2218-E-035-007. Authorized licensed use limited to: University of Prince Edward Island. Downloaded on June 20,2021 at 16:36:27 UTC from IEEE Xplore. Restrictions apply. stereo-vision, LiDAR, or ultrasonic sensor. The depth-based approach can measure the depth of the potholes and can also precept potholes in advance. However, potholes are often filled with snow and water. In this case, the depth-based approach will fail. 3) Image-based: The method that using images as the input can be divided into two categories by using deep learning or not. Both methods are described below: a) Non-deep-learning: Potholes are usually darker than their surroundings due to their depths. Therefore, the non-deep learning approaches usually design features according to the colors, such as Canny edge detection, histogram of oriented gradient, or watershed. Next, features are classified by manually defined thresholds or some machine learning algorithms, such as naive Bayes, k-means clustering, fuzzy Cmeans, support vector machine, or decision tree. However, the structure of potholes is and the contour is various. Thus, these manually designed features are imperfect to the real road environment, such as the reflection of water, shadow, potholes filled with snow, or the stains on the road. There is a research [3] aiming to distinguish potholes from shadows by manually defining more conditions. However, the conditions are based on some predefined shape parameters, such as the maximum length of the contour. Therefore, it is only suitable for specific test conditions because the contours of potholes are various in the real world. b) Deep-learning: Instead of doing feature engineering, the deep learning based methods can extract the feature of potholes automatically by training on pothole datasets. On the other hand, this also means less bias from experience or intuition. The deep learning based method can be divided into three categories by their tasks: image classification, object detection, and semantic segmentation. Image classification [4], which classifying images into potholes or non-potholes, requires few computational resources. However, it can only distinguish whether there is a pothole in the whole image, the region of interest(ROI), or the manually cropped image. With only this information, it’s difficult for a pothole detection system to perform some precise actions, e.g., recommends driving to the right because of the potholes on the left side of the road. Object detection can locate potholes with bounding boxes, so it needs more computational resources than image classification. In addition, it worth noting that the research [5] points out that adjacent potholes can be regarded as several potholes or one large pothole. This problem can affect the evaluation result which is using the evaluation metric based on numbers. Semantic segmentation [5] marking the potholes precisely with pixel-level masks requires the most computational resource. B. Autonomous driving The system structure of the proposed autonomous vehicle can be divided into three categories: modular pipelines [6], end to end [7] and direct perception [8]. 1) Modular pipeline: The main concept of the modular pipeline is divide and conquer, in other words, it isolates each function to a single modal. For sensing, modular will try to isolate each sensor to a single modal, such as lidar perception modal, image perception modal and high definition maps modal. For perception, there will be pedestrian recognition modal, vehicle recognition modal and traffic sign recognize modal. In conclusion, the modular pipeline has a clear structure, and it is easy to explain. In addition, the research [9] points out that the modular pipeline is helpful in virtual-to-real-world transfer. 2) End to end: The end to end based approach usually makes a deep neuron network learn how to drive from human driving experiences through imitation learning. The research [10] makes a car drive on the road and avoid obstacles successfully, it uses imitation learning to train a neuron network. The network consists of eight convolutional layers and two fully connected layers, and the action space has two dimensions: acceleration and steering. However, this kind of approach requires a lot of training data from humans to make the model learn such complex mapping. Besides, it is hard to understand the relationship between the input and the output compare to the modular pipeline. 3) Direct perception: The intelligibility of direct perception is between the modular pipeline and the end to end based approaches. First, it will map the input data to affordances, which are some understandable features, such as the angle of a lane tangent, the distance to the left lane, or the distance to the front car. Next, it will execute the driving strategy according to a rule-based controller. This structure has the same advantage as the modular pipeline: easy to explain. However, it also has the same disadvantage as the end to end approach: requires a lot of human driving experience as training data. Besides, the research [11] from NVIDIA uses the image of the front road and the steering angle applied by human drivers as input data and labels. The experimental result shows that the end-to-end CNN model can learn to recognize the lane without providing any information about the lane. The network consists of 20 convolution layers and four fully connected layers, and the Fig. 1. Bounding boxes cannot represent potholes on roads precisely. The green region is a pixel-level mask covering a pothole. The red rectangle is a bounding box. And the orange area in the bounding box does not belong to the pothole. As you can see, more than half of the areas in the bounding box are not potholes. Authorized licensed use limited to: University of Prince Edward Island. Downloaded on June 20,2021 at 16:36:27 UTC from IEEE Xplore. Restrictions apply. output is low-level driving decisions, such as the throttle and the steering angle. III. METHODOLOGY In this study, we proposed two systems: pothole detection system and pothole avoidance system. Follows will describe the approach of each system. A. Pothole detection system The purpose of the system is to warn the driver or to provide the position of potholes to an autonomous driving system for making better driving decisions. For example, it can warn the driver to avoid potholes or slow down to decrease the damages from hitting potholes. As mentioned in Section II, there are three types of tasks that have been used for pothole detection: image classification, object detection, and semantic segmentation. In this study, we chose object detection for detecting potholes, because of the following reasons: x Image classification cannot locate pothole in a whole image. Therefore, it is not taken into account. x Semantic segmentation is suitable for representing potholes with complex shapes. However, it requires a lot of computational power, but the computation power of an edge platform is limited. x Semantic segmentation requires pixel-level annotations, which are very expensive and hard to implement or maintain. However, bounding boxes cannot represent the potholes very well, as shown in Fig. 1. To make the bounding box more precise, we propose an approximate transformation method that can effectively reduce redundant areas. The approach consists of two steps: bounding box calibration and perspective bounding box transformation. Fig. 2. The symbol reference diagram of bounding box calibration. Note that we assumed that the vanishing point is known, it can easily be found by lane lines. The green rectangle is the original bounding box located by four coordinates: (xo,yt), (xi,yt), (xo,yb), and (xi,yb). The yellow rectangle is the calibrated bounding box. Einside and Eoutside are the errors that need to be calibrated. (VPx, VPy) is the position of the vanishing point. Hb is the height of the bounding box. VPh is the distance from the vanishing point to the bottom of the image. Himg is the height of the image. The symbol with a subscript i or inside means it is closer to x = VPx than the other symbol. If the bounding box crossed the x = VPx, then the subscript of symbols is o or outside. Fig. 3. Perspective bounding box transformation. (Ixo, yt) is the point where the line formed by (VPx, VPy) and (pxo, yb) intersects y = yt. And (Ixi, yb) is the point where the line formed by (VPx, VPy) and (pxi, yt) intersects y = yb. First, we need to calibrate the bounding box with ܧ௡௜௦௜ௗ௘ and ܧ௢௨௧௦௜ௗ௘ shown in Fig. 2. ܧ௡௜௦௜ௗ௘ and ܧ௢௨௧௦௜ௗ௘can be calculated by (1). After the bounding box calibration, the bounding box is then transferred to the perspective bounding box. As shown in Fig. 3, (Ixo, yt), (pxi, yt), (Ixi, yb), and (pxo, yb) are the four coordinates of the perspective bounding box. To have both performance and speed on edge platforms, we choose YOLOv3 after evaluated several models, the evaluation results are shown in. The deep learning based object detection model is a compute-intensive task, therefore, most of the researches use the GPU or the TPU to deal with such heavy workloads. However, the vehicle cannot afford a system with GPU or TPU due to the high power consumption. To decrease the requirements of computational resources, we quantize the YOLOv3 model before deploying it to an edge platform. Compared with the original model, the quantified model is only 23% of the size. Finally, we design an area-based perception method for the pothole detection system. The areas are designed according to the actions that the driver and the vehicle can take. This method mitigates the problem of unreliable evaluation results based on numbers. More details will describe in the evaluation results. TABLE I EVALUATION RESULT OF OBJECT DETECTION MODELS (1) Architecture Input Size Backbone Nvidia RTX2070 Xilinx ZCU104 YOLOv3 416 × 416 Darknet 53 49.7 29.3 YOLOv3-tiny 416 × 416 Simplified backbone 92.2 - YOLOv2 448 × 448 Darknet 19 - 58.5 SSD 300 × 300 MobileNet v2 - 177.6 512 × 512 27.4 - SSD with FPN 640 × 640 ResNet 50 - 6.1 Faster R-CNN 416 × 416 ResNet 101 13.3 - Retinanet 640 × 480 ResNet 50 37.3 - Unit: frames per second (FPS) Eoutside Einside (xi , yt (x ) o, yt ) (xi , yb (x ) o, yb) Himg (VPx, VPy) Hb VPh (VPx, VPy) (Ixi , yb) (Ixo, yt ) (xi + Einside, yt ) = (pxi, yt ) (xo - Eoutside, yb) = (pxo, yb) Authorized licensed use limited to: University of Prince Edward Island. Downloaded on June 20,2021 at 16:36:27 UTC from IEEE Xplore. Restrictions apply.\n",
            "Answer: [SEP]\n"
          ]
        }
      ]
    }
  ]
}